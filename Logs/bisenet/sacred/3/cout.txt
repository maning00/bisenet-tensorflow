INFO - bisenet-v2 - Running command 'main'
INFO - bisenet-v2 - Started run with ID "3"
INFO - root - nvidia-ml-py is not installed, automatically select gpu is disabled!
INFO - root - Creating training directory: Logs/bisenet/checkpoints/bisenet-v2
WARNING:tensorflow:From train.py:107: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING - tensorflow - From train.py:107: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING - root - img_mean is not explicitly specified, using default value: None
WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.read_file is deprecated. Please use tf.io.read_file instead.

WARNING - tensorflow - From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.read_file is deprecated. Please use tf.io.read_file instead.

WARNING:tensorflow:From /home/ubuntu/bisenet-tensorflow-master/Dataset/dataset.py:102: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING - tensorflow - From /home/ubuntu/bisenet-tensorflow-master/Dataset/dataset.py:102: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO - root - preproces -- augment
WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING - tensorflow - From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING - tensorflow - From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
/home/ubuntu/bisenet-tensorflow-master/Dataset/dataset.py:220: UserWarning: Seed 123 from outer graph might be getting used by function Dataset_map__image_mirroring, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  dataset = dataset.map(_image_mirroring, num_parallel_calls=threads)
WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

WARNING - tensorflow - From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

WARNING - tensorflow - From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

WARNING:tensorflow:From /home/ubuntu/bisenet-tensorflow-master/Dataset/dataset.py:121: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING - tensorflow - From /home/ubuntu/bisenet-tensorflow-master/Dataset/dataset.py:121: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
/home/ubuntu/bisenet-tensorflow-master/Dataset/dataset.py:222: UserWarning: Seed 123 from outer graph might be getting used by function Dataset_map__image_scaling, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  dataset = dataset.map(_image_scaling, num_parallel_calls=threads)
WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

WARNING - tensorflow - From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.

/home/ubuntu/bisenet-tensorflow-master/Dataset/dataset.py:225: UserWarning: Seed 123 from outer graph might be getting used by function Dataset_map_<lambda>, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  num_parallel_calls=threads)
/home/ubuntu/bisenet-tensorflow-master/Dataset/dataset.py:226: UserWarning: Seed 123 from outer graph might be getting used by function Dataset_map_<lambda>, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  dataset = dataset.map(lambda image, label: _apply_with_random_selector(image, lambda x, ordering: _distort_color
WARNING:tensorflow:From /home/ubuntu/bisenet-tensorflow-master/Dataset/dataset.py:237: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
WARNING - tensorflow - From /home/ubuntu/bisenet-tensorflow-master/Dataset/dataset.py:237: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
WARNING:tensorflow:From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:182: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING - tensorflow - From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:182: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING - tensorflow - From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:204: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

WARNING - tensorflow - From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:204: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

WARNING:tensorflow:From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:242: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING - tensorflow - From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:242: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:246: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

WARNING - tensorflow - From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:246: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

WARNING:tensorflow:From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:249: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.

WARNING - tensorflow - From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:249: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.

WARNING:tensorflow:From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:254: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING - tensorflow - From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:254: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING:tensorflow:From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:261: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING - tensorflow - From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:261: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:265: streaming_accuracy (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.metrics.accuracy. Note that the order of the labels and predictions arguments has been switched.
WARNING - tensorflow - From /home/ubuntu/bisenet-tensorflow-master/models/bisenet.py:265: streaming_accuracy (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.metrics.accuracy. Note that the order of the labels and predictions arguments has been switched.
WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/metrics_impl.py:1178: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING - tensorflow - From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/metrics_impl.py:1178: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING - root - img_mean is not explicitly specified, using default value: None
WARNING - root - random_scale is not explicitly specified, using default value: False
WARNING - root - random_mirror is not explicitly specified, using default value: True
INFO - root - preproces -- None
WARNING:tensorflow:From train.py:78: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

WARNING - tensorflow - From train.py:78: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

WARNING:tensorflow:From train.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING - tensorflow - From train.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From train.py:133: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING - tensorflow - From train.py:133: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:133: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING - tensorflow - From train.py:133: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:136: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING - tensorflow - From train.py:136: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:137: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING - tensorflow - From train.py:137: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From train.py:139: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING - tensorflow - From train.py:139: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:140: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.

WARNING - tensorflow - From train.py:140: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.

WARNING:tensorflow:From train.py:144: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

WARNING - tensorflow - From train.py:144: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

WARNING:tensorflow:From train.py:145: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING - tensorflow - From train.py:145: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:147: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING - tensorflow - From train.py:147: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

INFO - root - Train for 3750 steps
INFO - root - 2020-04-09 13:58:43.815632: step 0, total loss = 12.89, predict loss = 4.93 (0.3 examples/sec; 23.913 sec/batch; 24h:54m:33s remains)
INFO - root - 2020-04-09 13:59:04.292176: step 10, total loss = 3.55, predict loss = 1.50 (5.5 examples/sec; 1.452 sec/batch; 1h:30m:30s remains)
INFO - root - 2020-04-09 13:59:31.153598: step 20, total loss = 1.76, predict loss = 0.11 (5.5 examples/sec; 1.461 sec/batch; 1h:30m:50s remains)
INFO - root - 2020-04-09 13:59:57.366370: step 30, total loss = 3.44, predict loss = 0.29 (5.5 examples/sec; 1.467 sec/batch; 1h:30m:58s remains)
INFO - root - 2020-04-09 14:00:23.048156: step 40, total loss = 1.91, predict loss = 0.30 (5.5 examples/sec; 1.454 sec/batch; 1h:29m:56s remains)
INFO - root - 2020-04-09 14:00:49.149946: step 50, total loss = 0.72, predict loss = 0.06 (5.5 examples/sec; 1.456 sec/batch; 1h:29m:45s remains)
INFO - root - 2020-04-09 14:01:14.834384: step 60, total loss = 0.67, predict loss = 0.05 (5.5 examples/sec; 1.456 sec/batch; 1h:29m:31s remains)
INFO - root - 2020-04-09 14:01:29.568299: step 70, total loss = 0.79, predict loss = 0.11 (11.1 examples/sec; 0.719 sec/batch; 0h:44m:05s remains)
INFO - root - 2020-04-09 14:01:55.354012: step 80, total loss = 0.47, predict loss = 0.03 (5.5 examples/sec; 1.459 sec/batch; 1h:29m:13s remains)
INFO - root - 2020-04-09 14:02:20.402994: step 90, total loss = 1.31, predict loss = 0.13 (5.4 examples/sec; 1.483 sec/batch; 1h:30m:26s remains)
INFO - root - 2020-04-09 14:02:45.357075: step 100, total loss = 0.64, predict loss = 0.04 (5.5 examples/sec; 1.453 sec/batch; 1h:28m:21s remains)
INFO - root - 2020-04-09 14:03:11.632833: step 110, total loss = 0.31, predict loss = 0.02 (5.5 examples/sec; 1.454 sec/batch; 1h:28m:12s remains)
INFO - root - 2020-04-09 14:03:36.773255: step 120, total loss = 0.39, predict loss = 0.05 (5.4 examples/sec; 1.481 sec/batch; 1h:29m:35s remains)
INFO - root - 2020-04-09 14:04:02.054140: step 130, total loss = 0.25, predict loss = 0.03 (0.7 examples/sec; 12.023 sec/batch; 12h:05m:25s remains)
INFO - root - 2020-04-09 14:04:17.532051: step 140, total loss = 0.59, predict loss = 0.07 (5.5 examples/sec; 1.459 sec/batch; 1h:27m:48s remains)
INFO - root - 2020-04-09 14:04:42.642833: step 150, total loss = 0.31, predict loss = 0.03 (5.5 examples/sec; 1.455 sec/batch; 1h:27m:18s remains)
INFO - root - 2020-04-09 14:05:08.921086: step 160, total loss = 0.54, predict loss = 0.12 (5.5 examples/sec; 1.458 sec/batch; 1h:27m:15s remains)
INFO - root - 2020-04-09 14:05:34.418684: step 170, total loss = 0.46, predict loss = 0.06 (5.5 examples/sec; 1.455 sec/batch; 1h:26m:49s remains)
INFO - root - 2020-04-09 14:06:00.119976: step 180, total loss = 0.70, predict loss = 0.06 (5.5 examples/sec; 1.458 sec/batch; 1h:26m:43s remains)
INFO - root - 2020-04-09 14:06:25.206366: step 190, total loss = 0.33, predict loss = 0.02 (5.5 examples/sec; 1.454 sec/batch; 1h:26m:16s remains)
INFO - root - 2020-04-09 14:06:39.917167: step 200, total loss = 0.69, predict loss = 0.14 (11.0 examples/sec; 0.726 sec/batch; 0h:42m:57s remains)
INFO - root - 2020-04-09 14:07:08.154357: step 210, total loss = 0.44, predict loss = 0.09 (5.5 examples/sec; 1.464 sec/batch; 1h:26m:22s remains)
INFO - root - 2020-04-09 14:07:33.503129: step 220, total loss = 0.55, predict loss = 0.15 (5.5 examples/sec; 1.458 sec/batch; 1h:25m:46s remains)
INFO - root - 2020-04-09 14:07:59.714955: step 230, total loss = 0.54, predict loss = 0.05 (5.5 examples/sec; 1.461 sec/batch; 1h:25m:43s remains)
INFO - root - 2020-04-09 14:08:24.495137: step 240, total loss = 0.33, predict loss = 0.03 (5.5 examples/sec; 1.459 sec/batch; 1h:25m:22s remains)
INFO - root - 2020-04-09 14:08:49.191828: step 250, total loss = 0.28, predict loss = 0.05 (5.5 examples/sec; 1.456 sec/batch; 1h:24m:54s remains)
INFO - root - 2020-04-09 14:09:14.500502: step 260, total loss = 0.44, predict loss = 0.19 (0.7 examples/sec; 12.012 sec/batch; 11h:38m:43s remains)
INFO - root - 2020-04-09 14:09:30.850006: step 270, total loss = 0.24, predict loss = 0.03 (5.5 examples/sec; 1.454 sec/batch; 1h:24m:19s remains)
INFO - root - 2020-04-09 14:09:56.515613: step 280, total loss = 0.20, predict loss = 0.02 (5.5 examples/sec; 1.459 sec/batch; 1h:24m:23s remains)
INFO - root - 2020-04-09 14:10:21.704022: step 290, total loss = 0.73, predict loss = 0.05 (5.5 examples/sec; 1.460 sec/batch; 1h:24m:13s remains)
INFO - root - 2020-04-09 14:10:47.473622: step 300, total loss = 0.70, predict loss = 0.15 (5.5 examples/sec; 1.461 sec/batch; 1h:23m:59s remains)
INFO - root - 2020-04-09 14:11:13.106304: step 310, total loss = 0.29, predict loss = 0.04 (5.5 examples/sec; 1.462 sec/batch; 1h:23m:49s remains)
INFO - root - 2020-04-09 14:11:39.384775: step 320, total loss = 0.35, predict loss = 0.02 (5.5 examples/sec; 1.455 sec/batch; 1h:23m:11s remains)
INFO - root - 2020-04-09 14:11:54.132178: step 330, total loss = 0.28, predict loss = 0.01 (11.0 examples/sec; 0.730 sec/batch; 0h:41m:35s remains)
INFO - root - 2020-04-09 14:12:19.283643: step 340, total loss = 0.90, predict loss = 0.28 (5.5 examples/sec; 1.453 sec/batch; 1h:22m:35s remains)
INFO - root - 2020-04-09 14:12:45.189191: step 350, total loss = 0.27, predict loss = 0.01 (5.5 examples/sec; 1.456 sec/batch; 1h:22m:31s remains)
INFO - root - 2020-04-09 14:13:10.146793: step 360, total loss = 1.27, predict loss = 0.16 (5.5 examples/sec; 1.453 sec/batch; 1h:22m:04s remains)
INFO - root - 2020-04-09 14:13:37.300419: step 370, total loss = 0.79, predict loss = 0.16 (5.5 examples/sec; 1.466 sec/batch; 1h:22m:36s remains)
INFO - root - 2020-04-09 14:14:02.205768: step 380, total loss = 0.65, predict loss = 0.15 (5.5 examples/sec; 1.458 sec/batch; 1h:21m:51s remains)
INFO - root - 2020-04-09 14:14:27.278759: step 390, total loss = 0.31, predict loss = 0.05 (0.7 examples/sec; 11.815 sec/batch; 11h:01m:38s remains)
INFO - root - 2020-04-09 14:14:42.748460: step 400, total loss = 0.76, predict loss = 0.24 (5.5 examples/sec; 1.459 sec/batch; 1h:21m:26s remains)
INFO - root - 2020-04-09 14:15:09.299721: step 410, total loss = 0.30, predict loss = 0.03 (5.5 examples/sec; 1.459 sec/batch; 1h:21m:11s remains)
INFO - root - 2020-04-09 14:15:35.458328: step 420, total loss = 0.57, predict loss = 0.09 (5.4 examples/sec; 1.474 sec/batch; 1h:21m:48s remains)
INFO - root - 2020-04-09 14:16:01.232590: step 430, total loss = 0.23, predict loss = 0.03 (5.5 examples/sec; 1.450 sec/batch; 1h:20m:14s remains)
INFO - root - 2020-04-09 14:16:26.316694: step 440, total loss = 0.35, predict loss = 0.03 (5.5 examples/sec; 1.451 sec/batch; 1h:20m:02s remains)
INFO - root - 2020-04-09 14:16:51.473329: step 450, total loss = 0.37, predict loss = 0.06 (5.5 examples/sec; 1.456 sec/batch; 1h:20m:05s remains)
INFO - root - 2020-04-09 14:17:06.244214: step 460, total loss = 0.34, predict loss = 0.06 (10.8 examples/sec; 0.739 sec/batch; 0h:40m:30s remains)
INFO - root - 2020-04-09 14:17:32.636778: step 470, total loss = 0.50, predict loss = 0.02 (5.5 examples/sec; 1.454 sec/batch; 1h:19m:30s remains)
INFO - root - 2020-04-09 14:17:57.839441: step 480, total loss = 0.32, predict loss = 0.03 (5.5 examples/sec; 1.457 sec/batch; 1h:19m:23s remains)
INFO - root - 2020-04-09 14:18:23.259566: step 490, total loss = 0.49, predict loss = 0.11 (5.5 examples/sec; 1.455 sec/batch; 1h:19m:04s remains)
INFO - root - 2020-04-09 14:18:48.399420: step 500, total loss = 0.25, predict loss = 0.03 (5.5 examples/sec; 1.455 sec/batch; 1h:18m:47s remains)
INFO - root - 2020-04-09 14:19:13.857837: step 510, total loss = 0.60, predict loss = 0.05 (5.5 examples/sec; 1.452 sec/batch; 1h:18m:25s remains)
INFO - root - 2020-04-09 14:19:39.369345: step 520, total loss = 0.53, predict loss = 0.02 (0.7 examples/sec; 12.285 sec/batch; 11h:01m:20s remains)
INFO - root - 2020-04-09 14:19:55.732269: step 530, total loss = 0.30, predict loss = 0.01 (5.5 examples/sec; 1.455 sec/batch; 1h:18m:06s remains)
INFO - root - 2020-04-09 14:20:21.158076: step 540, total loss = 0.23, predict loss = 0.01 (5.5 examples/sec; 1.464 sec/batch; 1h:18m:20s remains)
INFO - root - 2020-04-09 14:20:46.899040: step 550, total loss = 0.56, predict loss = 0.02 (5.5 examples/sec; 1.454 sec/batch; 1h:17m:32s remains)
INFO - root - 2020-04-09 14:21:12.272794: step 560, total loss = 0.79, predict loss = 0.28 (5.5 examples/sec; 1.451 sec/batch; 1h:17m:09s remains)
INFO - root - 2020-04-09 14:21:37.724314: step 570, total loss = 0.24, predict loss = 0.03 (5.5 examples/sec; 1.454 sec/batch; 1h:17m:04s remains)
INFO - root - 2020-04-09 14:22:04.173534: step 580, total loss = 0.17, predict loss = 0.02 (5.5 examples/sec; 1.463 sec/batch; 1h:17m:17s remains)
INFO - root - 2020-04-09 14:22:18.902504: step 590, total loss = 0.30, predict loss = 0.03 (11.2 examples/sec; 0.717 sec/batch; 0h:37m:44s remains)
INFO - root - 2020-04-09 14:22:43.441897: step 600, total loss = 0.29, predict loss = 0.07 (5.4 examples/sec; 1.476 sec/batch; 1h:17m:28s remains)
INFO - root - 2020-04-09 14:23:09.405369: step 610, total loss = 1.69, predict loss = 0.59 (5.5 examples/sec; 1.460 sec/batch; 1h:16m:24s remains)
INFO - root - 2020-04-09 14:23:35.254217: step 620, total loss = 0.26, predict loss = 0.04 (5.5 examples/sec; 1.452 sec/batch; 1h:15m:45s remains)
INFO - root - 2020-04-09 14:24:01.301163: step 630, total loss = 0.61, predict loss = 0.12 (5.5 examples/sec; 1.457 sec/batch; 1h:15m:45s remains)
INFO - root - 2020-04-09 14:24:26.570665: step 640, total loss = 0.26, predict loss = 0.03 (5.5 examples/sec; 1.457 sec/batch; 1h:15m:32s remains)
INFO - root - 2020-04-09 14:24:51.372311: step 650, total loss = 0.11, predict loss = 0.01 (0.7 examples/sec; 11.569 sec/batch; 9h:57m:45s remains)
INFO - root - 2020-04-09 14:25:06.835522: step 660, total loss = 0.12, predict loss = 0.01 (5.5 examples/sec; 1.450 sec/batch; 1h:14m:41s remains)
INFO - root - 2020-04-09 14:25:31.506959: step 670, total loss = 0.40, predict loss = 0.17 (5.5 examples/sec; 1.452 sec/batch; 1h:14m:31s remains)
INFO - root - 2020-04-09 14:25:57.978101: step 680, total loss = 0.51, predict loss = 0.08 (5.5 examples/sec; 1.463 sec/batch; 1h:14m:50s remains)
INFO - root - 2020-04-09 14:26:23.755297: step 690, total loss = 0.44, predict loss = 0.20 (5.5 examples/sec; 1.454 sec/batch; 1h:14m:09s remains)
INFO - root - 2020-04-09 14:26:48.665638: step 700, total loss = 0.50, predict loss = 0.08 (5.5 examples/sec; 1.454 sec/batch; 1h:13m:55s remains)
INFO - root - 2020-04-09 14:27:14.617331: step 710, total loss = 0.49, predict loss = 0.08 (5.5 examples/sec; 1.462 sec/batch; 1h:14m:04s remains)
INFO - root - 2020-04-09 14:27:29.321002: step 720, total loss = 0.37, predict loss = 0.07 (10.9 examples/sec; 0.733 sec/batch; 0h:37m:01s remains)
INFO - root - 2020-04-09 14:27:56.893162: step 730, total loss = 0.31, predict loss = 0.07 (5.5 examples/sec; 1.452 sec/batch; 1h:13m:06s remains)
INFO - root - 2020-04-09 14:28:21.545026: step 740, total loss = 0.16, predict loss = 0.02 (5.5 examples/sec; 1.455 sec/batch; 1h:12m:59s remains)
INFO - root - 2020-04-09 14:28:48.085817: step 750, total loss = 0.45, predict loss = 0.04 (5.5 examples/sec; 1.459 sec/batch; 1h:12m:58s remains)
INFO - root - 2020-04-09 14:29:12.954614: step 760, total loss = 0.67, predict loss = 0.04 (5.5 examples/sec; 1.447 sec/batch; 1h:12m:05s remains)
INFO - root - 2020-04-09 14:29:37.494427: step 770, total loss = 0.70, predict loss = 0.07 (5.5 examples/sec; 1.454 sec/batch; 1h:12m:13s remains)
INFO - root - 2020-04-09 14:30:02.443809: step 780, total loss = 0.62, predict loss = 0.08 (0.7 examples/sec; 11.698 sec/batch; 9h:39m:03s remains)
INFO - root - 2020-04-09 14:30:18.803358: step 790, total loss = 0.38, predict loss = 0.10 (5.5 examples/sec; 1.454 sec/batch; 1h:11m:45s remains)
INFO - root - 2020-04-09 14:30:44.740959: step 800, total loss = 0.30, predict loss = 0.03 (5.5 examples/sec; 1.454 sec/batch; 1h:11m:29s remains)
INFO - root - 2020-04-09 14:31:09.638597: step 810, total loss = 1.92, predict loss = 0.15 (5.5 examples/sec; 1.453 sec/batch; 1h:11m:11s remains)
INFO - root - 2020-04-09 14:31:34.058208: step 820, total loss = 0.56, predict loss = 0.06 (5.5 examples/sec; 1.453 sec/batch; 1h:10m:57s remains)
INFO - root - 2020-04-09 14:31:59.458312: step 830, total loss = 0.45, predict loss = 0.03 (5.5 examples/sec; 1.462 sec/batch; 1h:11m:10s remains)
INFO - root - 2020-04-09 14:32:25.187933: step 840, total loss = 0.63, predict loss = 0.02 (5.5 examples/sec; 1.454 sec/batch; 1h:10m:30s remains)
INFO - root - 2020-04-09 14:32:39.870328: step 850, total loss = 0.25, predict loss = 0.02 (11.1 examples/sec; 0.718 sec/batch; 0h:34m:41s remains)
INFO - root - 2020-04-09 14:33:05.403901: step 860, total loss = 1.09, predict loss = 0.08 (5.5 examples/sec; 1.451 sec/batch; 1h:09m:52s remains)
INFO - root - 2020-04-09 14:33:30.985493: step 870, total loss = 0.31, predict loss = 0.02 (5.5 examples/sec; 1.466 sec/batch; 1h:10m:21s remains)
INFO - root - 2020-04-09 14:33:55.451411: step 880, total loss = 0.32, predict loss = 0.02 (5.5 examples/sec; 1.455 sec/batch; 1h:09m:34s remains)
INFO - root - 2020-04-09 14:34:21.432090: step 890, total loss = 0.50, predict loss = 0.11 (5.5 examples/sec; 1.455 sec/batch; 1h:09m:21s remains)
INFO - root - 2020-04-09 14:34:46.181620: step 900, total loss = 0.29, predict loss = 0.08 (5.5 examples/sec; 1.453 sec/batch; 1h:09m:02s remains)
INFO - root - 2020-04-09 14:35:12.110912: step 910, total loss = 0.12, predict loss = 0.03 (0.6 examples/sec; 12.649 sec/batch; 9h:58m:42s remains)
INFO - root - 2020-04-09 14:35:27.569434: step 920, total loss = 0.12, predict loss = 0.02 (5.5 examples/sec; 1.464 sec/batch; 1h:09m:03s remains)
INFO - root - 2020-04-09 14:35:52.711637: step 930, total loss = 0.10, predict loss = 0.01 (5.5 examples/sec; 1.453 sec/batch; 1h:08m:18s remains)
INFO - root - 2020-04-09 14:36:18.976765: step 940, total loss = 0.29, predict loss = 0.08 (5.5 examples/sec; 1.454 sec/batch; 1h:08m:05s remains)
INFO - root - 2020-04-09 14:36:43.786461: step 950, total loss = 0.17, predict loss = 0.03 (5.5 examples/sec; 1.460 sec/batch; 1h:08m:07s remains)
INFO - root - 2020-04-09 14:37:08.869116: step 960, total loss = 0.21, predict loss = 0.04 (5.5 examples/sec; 1.463 sec/batch; 1h:08m:00s remains)
INFO - root - 2020-04-09 14:37:33.505831: step 970, total loss = 0.24, predict loss = 0.06 (5.5 examples/sec; 1.454 sec/batch; 1h:07m:21s remains)
INFO - root - 2020-04-09 14:37:48.229300: step 980, total loss = 0.86, predict loss = 0.18 (11.1 examples/sec; 0.720 sec/batch; 0h:33m:13s remains)
INFO - root - 2020-04-09 14:38:14.797990: step 990, total loss = 0.11, predict loss = 0.03 (5.5 examples/sec; 1.460 sec/batch; 1h:07m:10s remains)
INFO - root - 2020-04-09 14:38:39.444381: step 1000, total loss = 0.08, predict loss = 0.02 (5.5 examples/sec; 1.454 sec/batch; 1h:06m:38s remains)
INFO - root - 2020-04-09 14:39:05.335672: step 1010, total loss = 0.13, predict loss = 0.05 (5.5 examples/sec; 1.454 sec/batch; 1h:06m:23s remains)
INFO - root - 2020-04-09 14:39:30.325044: step 1020, total loss = 0.10, predict loss = 0.02 (5.5 examples/sec; 1.458 sec/batch; 1h:06m:20s remains)
INFO - root - 2020-04-09 14:39:55.208778: step 1030, total loss = 0.12, predict loss = 0.03 (5.5 examples/sec; 1.464 sec/batch; 1h:06m:21s remains)
INFO - root - 2020-04-09 14:40:19.921827: step 1040, total loss = 0.42, predict loss = 0.05 (0.7 examples/sec; 11.448 sec/batch; 8h:37m:02s remains)
WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
WARNING - tensorflow - From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
INFO - root - 2020-04-09 14:40:36.312272: step 1050, total loss = 0.18, predict loss = 0.02 (5.4 examples/sec; 1.470 sec/batch; 1h:06m:09s remains)
INFO - root - 2020-04-09 14:41:01.631197: step 1060, total loss = 0.10, predict loss = 0.02 (5.5 examples/sec; 1.455 sec/batch; 1h:05m:14s remains)
INFO - root - 2020-04-09 14:41:26.579312: step 1070, total loss = 0.16, predict loss = 0.03 (5.5 examples/sec; 1.455 sec/batch; 1h:04m:58s remains)
INFO - root - 2020-04-09 14:41:51.623818: step 1080, total loss = 0.24, predict loss = 0.06 (5.5 examples/sec; 1.460 sec/batch; 1h:04m:59s remains)
INFO - root - 2020-04-09 14:42:17.763426: step 1090, total loss = 0.55, predict loss = 0.09 (5.5 examples/sec; 1.456 sec/batch; 1h:04m:33s remains)
INFO - root - 2020-04-09 14:42:43.664447: step 1100, total loss = 0.06, predict loss = 0.01 (5.5 examples/sec; 1.453 sec/batch; 1h:04m:10s remains)
INFO - root - 2020-04-09 14:42:58.408628: step 1110, total loss = 1.68, predict loss = 0.53 (11.2 examples/sec; 0.717 sec/batch; 0h:31m:33s remains)
INFO - root - 2020-04-09 14:43:24.404492: step 1120, total loss = 0.23, predict loss = 0.02 (5.5 examples/sec; 1.454 sec/batch; 1h:03m:43s remains)
INFO - root - 2020-04-09 14:43:50.585433: step 1130, total loss = 0.11, predict loss = 0.01 (5.5 examples/sec; 1.458 sec/batch; 1h:03m:39s remains)
INFO - root - 2020-04-09 14:44:15.913745: step 1140, total loss = 0.06, predict loss = 0.01 (5.5 examples/sec; 1.455 sec/batch; 1h:03m:18s remains)
INFO - root - 2020-04-09 14:44:43.481112: step 1150, total loss = 0.13, predict loss = 0.03 (5.5 examples/sec; 1.454 sec/batch; 1h:02m:59s remains)
INFO - root - 2020-04-09 14:45:07.931243: step 1160, total loss = 0.17, predict loss = 0.02 (5.5 examples/sec; 1.455 sec/batch; 1h:02m:47s remains)
INFO - root - 2020-04-09 14:45:33.394925: step 1170, total loss = 0.10, predict loss = 0.02 (0.7 examples/sec; 12.150 sec/batch; 8h:42m:26s remains)
INFO - root - 2020-04-09 14:45:48.838087: step 1180, total loss = 0.11, predict loss = 0.03 (5.5 examples/sec; 1.451 sec/batch; 1h:02m:09s remains)
INFO - root - 2020-04-09 14:46:12.878674: step 1190, total loss = 0.12, predict loss = 0.02 (5.5 examples/sec; 1.450 sec/batch; 1h:01m:53s remains)
INFO - root - 2020-04-09 14:46:39.299410: step 1200, total loss = 1.61, predict loss = 0.55 (5.5 examples/sec; 1.448 sec/batch; 1h:01m:32s remains)
INFO - root - 2020-04-09 14:47:04.708416: step 1210, total loss = 0.10, predict loss = 0.03 (5.5 examples/sec; 1.455 sec/batch; 1h:01m:36s remains)
INFO - root - 2020-04-09 14:47:30.300464: step 1220, total loss = 0.07, predict loss = 0.01 (5.5 examples/sec; 1.458 sec/batch; 1h:01m:29s remains)
INFO - root - 2020-04-09 14:47:55.324392: step 1230, total loss = 0.17, predict loss = 0.02 (5.5 examples/sec; 1.450 sec/batch; 1h:00m:54s remains)
INFO - root - 2020-04-09 14:48:10.050969: step 1240, total loss = 0.10, predict loss = 0.02 (11.1 examples/sec; 0.721 sec/batch; 0h:30m:09s remains)
INFO - root - 2020-04-09 14:48:37.424610: step 1250, total loss = 0.07, predict loss = 0.01 (5.5 examples/sec; 1.455 sec/batch; 1h:00m:38s remains)
INFO - root - 2020-04-09 14:49:03.010953: step 1260, total loss = 0.09, predict loss = 0.02 (5.5 examples/sec; 1.452 sec/batch; 1h:00m:15s remains)
INFO - root - 2020-04-09 14:49:28.244182: step 1270, total loss = 0.08, predict loss = 0.02 (5.5 examples/sec; 1.462 sec/batch; 1h:00m:25s remains)
INFO - root - 2020-04-09 14:49:53.352167: step 1280, total loss = 0.34, predict loss = 0.05 (5.5 examples/sec; 1.454 sec/batch; 0h:59m:51s remains)
INFO - root - 2020-04-09 14:50:18.382603: step 1290, total loss = 0.16, predict loss = 0.01 (5.4 examples/sec; 1.469 sec/batch; 1h:00m:12s remains)
INFO - root - 2020-04-09 14:50:43.131064: step 1300, total loss = 0.08, predict loss = 0.02 (0.7 examples/sec; 11.502 sec/batch; 7h:49m:40s remains)
INFO - root - 2020-04-09 14:50:59.529478: step 1310, total loss = 0.10, predict loss = 0.01 (5.5 examples/sec; 1.452 sec/batch; 0h:59m:01s remains)
INFO - root - 2020-04-09 14:51:25.577407: step 1320, total loss = 0.07, predict loss = 0.01 (5.5 examples/sec; 1.458 sec/batch; 0h:59m:02s remains)
INFO - root - 2020-04-09 14:51:51.241697: step 1330, total loss = 0.06, predict loss = 0.01 (5.5 examples/sec; 1.451 sec/batch; 0h:58m:31s remains)
INFO - root - 2020-04-09 14:52:16.079904: step 1340, total loss = 0.83, predict loss = 0.20 (5.5 examples/sec; 1.452 sec/batch; 0h:58m:19s remains)
INFO - root - 2020-04-09 14:52:40.872048: step 1350, total loss = 0.04, predict loss = 0.01 (5.5 examples/sec; 1.461 sec/batch; 0h:58m:25s remains)
INFO - root - 2020-04-09 14:53:07.021819: step 1360, total loss = 0.06, predict loss = 0.01 (5.4 examples/sec; 1.470 sec/batch; 0h:58m:32s remains)
INFO - root - 2020-04-09 14:53:21.750252: step 1370, total loss = 0.10, predict loss = 0.02 (11.1 examples/sec; 0.718 sec/batch; 0h:28m:29s remains)
INFO - root - 2020-04-09 14:53:46.665932: step 1380, total loss = 0.09, predict loss = 0.02 (5.4 examples/sec; 1.470 sec/batch; 0h:58m:04s remains)
INFO - root - 2020-04-09 14:54:12.036017: step 1390, total loss = 0.11, predict loss = 0.02 (5.5 examples/sec; 1.463 sec/batch; 0h:57m:32s remains)
INFO - root - 2020-04-09 14:54:36.411409: step 1400, total loss = 0.06, predict loss = 0.01 (5.5 examples/sec; 1.456 sec/batch; 0h:57m:01s remains)
INFO - root - 2020-04-09 14:55:02.580868: step 1410, total loss = 0.07, predict loss = 0.01 (5.5 examples/sec; 1.453 sec/batch; 0h:56m:40s remains)
INFO - root - 2020-04-09 14:55:27.974712: step 1420, total loss = 0.12, predict loss = 0.03 (5.5 examples/sec; 1.456 sec/batch; 0h:56m:31s remains)
INFO - root - 2020-04-09 14:55:53.059952: step 1430, total loss = 0.20, predict loss = 0.06 (0.7 examples/sec; 11.811 sec/batch; 7h:36m:41s remains)
INFO - root - 2020-04-09 14:56:08.540248: step 1440, total loss = 0.22, predict loss = 0.07 (5.5 examples/sec; 1.449 sec/batch; 0h:55m:48s remains)
INFO - root - 2020-04-09 14:56:33.856746: step 1450, total loss = 0.05, predict loss = 0.01 (5.5 examples/sec; 1.457 sec/batch; 0h:55m:51s remains)
INFO - root - 2020-04-09 14:56:59.921035: step 1460, total loss = 0.11, predict loss = 0.03 (5.5 examples/sec; 1.458 sec/batch; 0h:55m:38s remains)
INFO - root - 2020-04-09 14:57:24.423073: step 1470, total loss = 1.99, predict loss = 0.49 (5.4 examples/sec; 1.474 sec/batch; 0h:56m:00s remains)
INFO - root - 2020-04-09 14:57:49.190388: step 1480, total loss = 0.15, predict loss = 0.03 (5.5 examples/sec; 1.455 sec/batch; 0h:55m:02s remains)
INFO - root - 2020-04-09 14:58:14.400722: step 1490, total loss = 0.11, predict loss = 0.02 (5.5 examples/sec; 1.458 sec/batch; 0h:54m:54s remains)
INFO - root - 2020-04-09 14:58:29.160796: step 1500, total loss = 0.06, predict loss = 0.00 (10.9 examples/sec; 0.732 sec/batch; 0h:27m:27s remains)
INFO - root - 2020-04-09 14:58:56.161956: step 1510, total loss = 0.08, predict loss = 0.01 (5.5 examples/sec; 1.462 sec/batch; 0h:54m:34s remains)
INFO - root - 2020-04-09 14:59:21.642800: step 1520, total loss = 0.08, predict loss = 0.02 (5.5 examples/sec; 1.456 sec/batch; 0h:54m:07s remains)
INFO - root - 2020-04-09 14:59:47.118216: step 1530, total loss = 0.06, predict loss = 0.01 (5.5 examples/sec; 1.457 sec/batch; 0h:53m:54s remains)
INFO - root - 2020-04-09 15:00:12.569493: step 1540, total loss = 0.07, predict loss = 0.01 (5.5 examples/sec; 1.454 sec/batch; 0h:53m:32s remains)
INFO - root - 2020-04-09 15:00:38.057794: step 1550, total loss = 0.06, predict loss = 0.01 (5.5 examples/sec; 1.457 sec/batch; 0h:53m:25s remains)
INFO - root - 2020-04-09 15:01:03.399817: step 1560, total loss = 0.11, predict loss = 0.01 (0.7 examples/sec; 12.041 sec/batch; 7h:19m:29s remains)
INFO - root - 2020-04-09 15:01:19.754538: step 1570, total loss = 0.07, predict loss = 0.01 (5.5 examples/sec; 1.455 sec/batch; 0h:52m:51s remains)
INFO - root - 2020-04-09 15:01:45.735740: step 1580, total loss = 0.09, predict loss = 0.02 (5.5 examples/sec; 1.458 sec/batch; 0h:52m:42s remains)
INFO - root - 2020-04-09 15:02:10.485336: step 1590, total loss = 0.08, predict loss = 0.01 (5.5 examples/sec; 1.454 sec/batch; 0h:52m:20s remains)
INFO - root - 2020-04-09 15:02:35.555685: step 1600, total loss = 0.05, predict loss = 0.01 (5.5 examples/sec; 1.458 sec/batch; 0h:52m:15s remains)
INFO - root - 2020-04-09 15:03:00.688590: step 1610, total loss = 0.06, predict loss = 0.01 (5.5 examples/sec; 1.455 sec/batch; 0h:51m:53s remains)
INFO - root - 2020-04-09 15:03:27.510699: step 1620, total loss = 0.09, predict loss = 0.02 (5.5 examples/sec; 1.456 sec/batch; 0h:51m:41s remains)
INFO - root - 2020-04-09 15:03:42.223571: step 1630, total loss = 0.24, predict loss = 0.02 (11.1 examples/sec; 0.718 sec/batch; 0h:25m:22s remains)
INFO - root - 2020-04-09 15:04:07.681052: step 1640, total loss = 0.15, predict loss = 0.01 (5.5 examples/sec; 1.450 sec/batch; 0h:50m:58s remains)
INFO - root - 2020-04-09 15:04:33.316424: step 1650, total loss = 0.07, predict loss = 0.01 (5.5 examples/sec; 1.455 sec/batch; 0h:50m:55s remains)
INFO - root - 2020-04-09 15:04:58.455113: step 1660, total loss = 0.05, predict loss = 0.00 (5.5 examples/sec; 1.457 sec/batch; 0h:50m:45s remains)
INFO - root - 2020-04-09 15:05:24.316023: step 1670, total loss = 0.06, predict loss = 0.00 (5.4 examples/sec; 1.469 sec/batch; 0h:50m:55s remains)
INFO - root - 2020-04-09 15:05:49.497494: step 1680, total loss = 0.07, predict loss = 0.01 (5.5 examples/sec; 1.466 sec/batch; 0h:50m:34s remains)
INFO - root - 2020-04-09 15:06:14.723762: step 1690, total loss = 0.09, predict loss = 0.01 (0.7 examples/sec; 11.938 sec/batch; 6h:49m:51s remains)
INFO - root - 2020-04-09 15:06:30.198417: step 1700, total loss = 0.04, predict loss = 0.01 (5.5 examples/sec; 1.458 sec/batch; 0h:49m:48s remains)
INFO - root - 2020-04-09 15:06:56.170080: step 1710, total loss = 0.13, predict loss = 0.02 (5.5 examples/sec; 1.451 sec/batch; 0h:49m:20s remains)
INFO - root - 2020-04-09 15:07:21.432304: step 1720, total loss = 0.05, predict loss = 0.01 (5.5 examples/sec; 1.452 sec/batch; 0h:49m:07s remains)
INFO - root - 2020-04-09 15:07:46.202523: step 1730, total loss = 0.05, predict loss = 0.01 (5.5 examples/sec; 1.458 sec/batch; 0h:49m:05s remains)
INFO - root - 2020-04-09 15:08:12.032760: step 1740, total loss = 0.04, predict loss = 0.00 (5.5 examples/sec; 1.457 sec/batch; 0h:48m:49s remains)
INFO - root - 2020-04-09 15:08:36.672818: step 1750, total loss = 0.04, predict loss = 0.00 (5.5 examples/sec; 1.455 sec/batch; 0h:48m:29s remains)
INFO - root - 2020-04-09 15:08:51.484216: step 1760, total loss = 0.07, predict loss = 0.01 (11.1 examples/sec; 0.721 sec/batch; 0h:23m:55s remains)
INFO - root - 2020-04-09 15:09:18.587288: step 1770, total loss = 0.10, predict loss = 0.03 (5.5 examples/sec; 1.454 sec/batch; 0h:47m:59s remains)
INFO - root - 2020-04-09 15:09:43.618158: step 1780, total loss = 0.04, predict loss = 0.01 (5.5 examples/sec; 1.455 sec/batch; 0h:47m:47s remains)
INFO - root - 2020-04-09 15:10:09.066338: step 1790, total loss = 0.06, predict loss = 0.01 (5.5 examples/sec; 1.455 sec/batch; 0h:47m:31s remains)
INFO - root - 2020-04-09 15:10:33.289351: step 1800, total loss = 0.07, predict loss = 0.00 (5.5 examples/sec; 1.453 sec/batch; 0h:47m:13s remains)
INFO - root - 2020-04-09 15:11:00.191519: step 1810, total loss = 0.05, predict loss = 0.01 (5.5 examples/sec; 1.452 sec/batch; 0h:46m:56s remains)
INFO - root - 2020-04-09 15:11:25.993800: step 1820, total loss = 0.04, predict loss = 0.01 (0.6 examples/sec; 12.522 sec/batch; 6h:42m:48s remains)
INFO - root - 2020-04-09 15:11:42.348602: step 1830, total loss = 0.04, predict loss = 0.00 (5.5 examples/sec; 1.458 sec/batch; 0h:46m:39s remains)
INFO - root - 2020-04-09 15:12:08.315382: step 1840, total loss = 0.08, predict loss = 0.01 (5.5 examples/sec; 1.450 sec/batch; 0h:46m:09s remains)
INFO - root - 2020-04-09 15:12:33.583541: step 1850, total loss = 0.15, predict loss = 0.04 (5.5 examples/sec; 1.450 sec/batch; 0h:45m:55s remains)
INFO - root - 2020-04-09 15:12:58.753652: step 1860, total loss = 0.09, predict loss = 0.01 (5.5 examples/sec; 1.453 sec/batch; 0h:45m:46s remains)
INFO - root - 2020-04-09 15:13:24.345064: step 1870, total loss = 0.09, predict loss = 0.02 (5.5 examples/sec; 1.461 sec/batch; 0h:45m:47s remains)
